{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "machine_learning_sar_tutorial_1_students.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akrambchiri123/deep-learning-coursera/blob/master/machine_learning_sar_tutorial_1_students.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0Wn_3UmGsmr"
      },
      "source": [
        "#Import libraries\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZYLTtmCE_Fp"
      },
      "source": [
        "**Question 1.** Load the first data set located in ${\\tt td\\_1\\_data\\_set\\_1\\_X.csv}$ and ${\\tt td\\_1\\_data\\_set\\_1\\_Y.csv}$ and visualize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5-ZwFnZGy7o",
        "outputId": "d9eb9480-4493-4aa9-a45b-91713514fecd"
      },
      "source": [
        "#Load data set 1\r\n",
        "X = np.loadtxt(open(\"machine_learning_sar_tutorial_1_data_set_1_X.csv\", \"rb\"), delimiter=\",\", skiprows=0)\r\n",
        "Y = np.loadtxt(open(\"machine_learning_sar_tutorial_1_data_set_1_Y.csv\", \"rb\"), delimiter=\",\", skiprows=0)\r\n",
        "#Display the first 10 data points\r\n",
        "\r\n",
        "for s in range(0,10):\r\n",
        "    print('Example ', s ,' : ', X[s])\r\n",
        "    print('Label ', s ,' : ', Y[s])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example  0  :  [ 1.6302   0.1236   1.0486  -2.5934   0.52915]\n",
            "Label  0  :  1.0\n",
            "Example  1  :  [ 0.48889  -0.086267 -0.95551   0.37085   0.36009 ]\n",
            "Label  1  :  -1.0\n",
            "Example  2  :  [ 1.0347  -0.08058  1.1108  -0.34862 -0.14144]\n",
            "Label  2  :  1.0\n",
            "Example  3  :  [ 0.72689 -0.41526  0.64704 -0.82162 -1.2841 ]\n",
            "Label  3  :  1.0\n",
            "Example  4  :  [-0.30344 -0.48195  0.6892   0.92909  0.64574]\n",
            "Label  4  :  -1.0\n",
            "Example  5  :  [ 0.29387   0.14733   0.82444  -0.023135  0.14593 ]\n",
            "Label  5  :  1.0\n",
            "Example  6  :  [-0.78728  0.30853 -1.504   -0.39958 -1.5664 ]\n",
            "Label  6  :  1.0\n",
            "Example  7  :  [ 0.8884  -0.95941  0.45263 -1.1902   0.77326]\n",
            "Label  7  :  1.0\n",
            "Example  8  :  [-1.1471   0.95293  0.43819 -1.7452  -1.013  ]\n",
            "Label  8  :  1.0\n",
            "Example  9  :  [-1.0689  -1.4003   0.66742  0.86717 -2.0899 ]\n",
            "Label  9  :  -1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKvLj1_1E_Fr"
      },
      "source": [
        "**Question 2.** Compute the error rate of an arbitrary linear classifier. Fill out the ${\\tt get\\_error}$ function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDZ2HAnfHF_m"
      },
      "source": [
        "def get_error(X,Y,w):\r\n",
        "    '''Compute the error of a classifier on a data set\r\n",
        " \r\n",
        "    Arguments\r\n",
        "    X: examples in the data set\r\n",
        "    Y: labels of examples in the data set\r\n",
        "    w: classifier\r\n",
        " \r\n",
        "    Return value\r\n",
        "    err: error rate of the classifier on the data set\r\n",
        "    '''\r\n",
        " \r\n",
        "    err = 0.0\r\n",
        "    for i in range(0,Y.shape[0]):\r\n",
        "        err = err + float(Y[i]*np.dot(X[i,:],w) <= 0)/Y.shape[0]\r\n",
        "    return err"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5SyxeQZE_Fu",
        "outputId": "154c140f-fe07-44ad-9986-3a627b21c228"
      },
      "source": [
        "#Compute the error rate of a well chosen classifier\n",
        "w = [1,1,0,-3,-1]\n",
        "t = get_error(X,Y,w)\n",
        "print('Classifier ', w/np.linalg.norm(w) ,' \\nError ', t)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier  [ 0.28867513  0.28867513  0.         -0.8660254  -0.28867513]  \n",
            "Error  0.15515515515515554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0354AUwE_Fv"
      },
      "source": [
        "**Question 3.** Run the variant of the perceptron algorithm described below on the data set for $T$ iterations for $T=10,100,1000,10000$ steps over $m=100$ examples. Report the outputted classifier and its training error. Fill out the ${\\tt perceptron}$ function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lfJDUhZE_Fw"
      },
      "source": [
        "***\n",
        "\n",
        "**Algorithm** Fast Perceptron  \n",
        "**Data** Examples $S = (x_1,y_1,...,x_m,y_m)$, number of iterations $T$  \n",
        "**Result** A separating hyperplane  \n",
        "$w(0) \\leftarrow 0$  \n",
        "**For** $t=1,...,T$ **do**  \n",
        "&emsp; Choose $i\\in \\{1,...,m\\}$ uniformly at random  \n",
        "&emsp; **If** $y_i w(t)^\\top x_i \\le 0$ **do**  \n",
        "&emsp; &emsp; $w(t+1) \\leftarrow w(t) + y_i x_i$  \n",
        "**End**  \n",
        "\n",
        "***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD6zgWyiHMfF"
      },
      "source": [
        "def perceptron(X,Y,T):\r\n",
        "    '''Run the perceptron algorithm on a data set\r\n",
        " \r\n",
        "    Arguments:\r\n",
        "    X: examples in the training set\r\n",
        "    Y: labels of examples in the training set\r\n",
        "    T: Maximal number of iterations\r\n",
        " \r\n",
        "    Return value\r\n",
        "    w: the classifier found after at most T iteration of the algorithm\r\n",
        "    '''\r\n",
        " \r\n",
        "    w = np.zeros(X.shape[1]) #initial classifier is the null vector\r\n",
        "    m = X.shape[0] #number of training examples\r\n",
        "    for t in range(0,T):\r\n",
        "        i = np.random.randint(0,m) #select an example at random\r\n",
        "        if (Y[i]*np.dot(X[i,:],w) <= 0):\r\n",
        "            w = w + Y[i]*X[i,:] #if the chosen example is incorrectly classified, add it to the current classifier\r\n",
        " \r\n",
        "    return w\r\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYQ1kB0vE_Fz",
        "outputId": "c42d8e06-eec4-46c7-f692-4439ccf4bd23"
      },
      "source": [
        "#Run the perceptron algorithm for T iterations\n",
        "T = 100000 #number of iterations\n",
        "w = perceptron(X,Y,T)\n",
        "#Compute the error rate of the resulting classifier\n",
        "t = get_error(X,Y,w)\n",
        "print('Classifier ', w/np.linalg.norm(w) ,'\\nError ', t)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier  [ 0.47612956  0.25453752  0.00500886 -0.57484923 -0.61484516] \n",
            "Error  0.005005005005005005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHZm0L7KE_Fz"
      },
      "source": [
        "**Question 4.** Perform a cross validation by splitting the data set in two parts for $m = 100$ and $T=1000$. Report the training error and the validation error. Fill out the  ${\\tt split}$ function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Htkq9IWGbxj"
      },
      "source": [
        "def split(X,Y,m):\r\n",
        "    '''Arguments:\r\n",
        " \r\n",
        "    X: examples in the data set\r\n",
        "    Y: labels of examples in the data set\r\n",
        "    m: number of examples in the training set\r\n",
        " \r\n",
        "    Return values\r\n",
        "    X_train: examples in the training set\r\n",
        "    Y_train: labels of examples in the training set\r\n",
        "    X_eval: examples in the validation set\r\n",
        "    Y_eval: labels of examples in the validation set\r\n",
        " \r\n",
        "    '''\r\n",
        "    #Split Data Set Into Training And Validation\r\n",
        "    p = np.random.permutation(X.shape[0])\r\n",
        "    train = p[0:m]\r\n",
        "    eval = p[m:(X.shape[0])]\r\n",
        "    if (X.ndim == 1):\r\n",
        "        X_train = X[train]\r\n",
        "        X_eval = X[eval]\r\n",
        "    else:\r\n",
        "        X_train = X[train,:]\r\n",
        "        X_eval = X[eval,:]\r\n",
        " \r\n",
        "    Y_train = Y[train]\r\n",
        "    Y_eval = Y[eval]\r\n",
        " \r\n",
        "    return X_train,Y_train,X_eval,Y_eval"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bjn_NgOoGi57",
        "outputId": "eabd0eb1-5414-4201-9590-69a5eaa70063"
      },
      "source": [
        "#Split the data set to perform cross validation\r\n",
        "m = 100 #number of examples in the training set\r\n",
        "X_train,Y_train,X_eval,Y_eval = split(X,Y,m)\r\n",
        "#Run the perceptron algorithm for T iterations\r\n",
        "T = 100000 #number of iterations\r\n",
        "w = perceptron(X_train,Y_train,T)\r\n",
        "#Compute the training and validation error of the resulting classifier\r\n",
        "t = get_error(X_train,Y_train,w)\r\n",
        "v = get_error(X_eval,Y_eval,w)\r\n",
        "print('Classifier ', w/np.linalg.norm(w) ,'\\nTraining Error ', t, '\\nValidation Error ',v)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier  [ 0.49262918  0.21951337 -0.00072737 -0.57645947 -0.61386018] \n",
            "Training Error  0.0 \n",
            "Validation Error  0.011123470522803115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ3-xTnRE_F2"
      },
      "source": [
        "**Question 5.** Now perform $100$ cross validations and average out to get the true validation error. What is the validation error for $m=50,100,200$ examples and $T$ suitably chosen ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lVOZP40E_F2"
      },
      "source": [
        "T = 10000 #number of iterations\n",
        "n = 100 #number of cross validations\n",
        "t_mean = 0 #to store the average training error\n",
        "v_mean = 0 #to store the average validation error\n",
        "for s in range(0,n):\n",
        "    #Split the data set to perform cross validation\n",
        "    m = 100 #number of examples in the training set\n",
        "    X_train,Y_train,X_eval,Y_eval = split(X,Y,m)\n",
        "    #Run the perceptron algorithm for T iterations over N cross validations\n",
        "    w = perceptron(X_train,Y_train,T)\n",
        "    #Compute the training and validation error of the resulting classifier\n",
        "    t = get_error(X_train,Y_train,w)\n",
        "    v = get_error(X_eval,Y_eval,w)\n",
        "    t_mean = ###FILL HERE \n",
        "    v_mean = ###FILL HERE\n",
        "\n",
        "print('Average Training Error ', t_mean, '\\nAverage Validation Error ',v_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9-SlUbPH8uK",
        "outputId": "7d53bd63-309b-4745-e541-a7e35e295259"
      },
      "source": [
        "T = 10000 #number of iterations\r\n",
        "n = 100 #number of cross validations\r\n",
        "t_mean = 0 #to store the average training error\r\n",
        "v_mean = 0 #to store the average validation error\r\n",
        "for s in range(0,n):\r\n",
        "    #Split the data set to perform cross validation\r\n",
        "    m = 100 #number of examples in the training set\r\n",
        "    X_train,Y_train,X_eval,Y_eval = split(X,Y,m)\r\n",
        "    #Run the perceptron algorithm for T iterations over N cross validations\r\n",
        "    w = perceptron(X_train,Y_train,T)\r\n",
        "    #Compute the training and validation error of the resulting classifier\r\n",
        "    t = get_error(X_train,Y_train,w)\r\n",
        "    v = get_error(X_eval,Y_eval,w)\r\n",
        "    t_mean = t_mean + t/n\r\n",
        "    v_mean = v_mean + v/n\r\n",
        " \r\n",
        "print('Average Training Error ', t_mean, '\\nAverage Validation Error ',v_mean)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Training Error  0.0009 \n",
            "Average Validation Error  0.025617352614015557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N9PEoXUE_F4"
      },
      "source": [
        "**Question 6.** Load the second data set located in \"machine_learning_sar_tutorial_1_data_set_2_X.csv\" and \"machine_learning_sar_tutorial_1_data_set_2_Y.csv\" and visualize it. Argue whether or not using linear classification is appropriate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "sZVLfyNuE_F5",
        "outputId": "dc388d1d-f583-4765-c65e-e6b2d863b3f2"
      },
      "source": [
        "#Load data set 2\n",
        "X = np.loadtxt(open(\"machine_learning_sar_tutorial_1_data_set_2_X.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
        "Y = np.loadtxt(open(\"machine_learning_sar_tutorial_1_data_set_2_Y.csv\", \"rb\"), delimiter=\",\", skiprows=0)\n",
        "#Visualize data\n",
        "plt.scatter(X,Y)\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUfUlEQVR4nO3df4xl5X3f8ffHS8CqYscLO6UU1iy2NzLERJDeABFSftiA16hiSUMdSKkXlwTJDakUN5ZxsURKQMKNWpy2tPYGY69/BEioYk+VuhQDLpLlpdytCb8izIId2A2GCb9SCQcCfPvHPWtdhpmdGe6dudx93i/pas55znPO/T7McD9zfsw+qSokSe1606QLkCRNlkEgSY0zCCSpcQaBJDXOIJCkxh006QJejw0bNtSmTZsmXYYkTZVdu3b9dVXNzG+fyiDYtGkT/X5/0mVI0lRJ8pcLtXtpSJIaZxBIUuMMAklqnEEgSY0zCCSpcWN5aijJdcA/Bp6sqvcssD3AHwBnAs8DF1TV/+22bQM+2XW9oqp2jKOm+U6+8hae+H8vrsah31DeFPi1k9/OFWcfP+lSpDX1ya/ey5d3PjrpMtbEqe88lK/8xs+N7XjjOiP4ArBlP9s/AGzuXhcB/xUgyaHAZcDJwEnAZUnWj6mmH2klBABeKfjyzkf55FfvnXQp0pppKQQAvvXw0/yzP/z22I43liCoqjuAp/fTZSvwxRrYCbwtyRHA+4FbqurpqnoGuIX9B8rr0koIDLv+zscmXYK0Zlr8ef/Ww/v7yF2ZtbpHcCQw/J3a07Ut1v4aSS5K0k/Sn5ubW7VCDxQvO8+EGuLP+2im5mZxVW2vql5V9WZmXvMX0ppnXTLpEqQ148/7aNYqCPYCG4fWj+raFmsfq8PfcvC4D/mGd97JG5fuJB0gWvx5P/Wdh47tWGsVBLPAhzJwCvBcVT0O3AyckWR9d5P4jK5trO689PRmwuBNgfNP8akhteWKs4/n/FPePuky1sy4nxrKOOYsTnI98IvABuAJBk8C/RhAVX2me3z0PzO4Efw88OGq6nf7/gvg33SHurKqPr/U+/V6vfIfnZOklUmyq6p689vH8ncEVXXeEtsL+M1Ftl0HXDeOOiRJKzc1N4slSavDIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxYwmCJFuSPJhkd5JLFth+dZK7u9d3kzw7tO3loW2z46hHkrR8I89QlmQdcA1wOrAHuCvJbFU9sK9PVf32UP/fAk4cOsQPq+qEUeuQJL0+4zgjOAnYXVWPVNWLwA3A1v30Pw+4fgzvK0kag3EEwZHAY0Pre7q210hyNHAMcNtQ85uT9JPsTHL2Ym+S5KKuX39ubm4MZUuSYO1vFp8L3FRVLw+1HV1VPeDXgE8needCO1bV9qrqVVVvZmZmLWqVpCaMIwj2AhuH1o/q2hZyLvMuC1XV3u7rI8A3efX9A0nSKhtHENwFbE5yTJKDGXzYv+bpnyTvBtYD3x5qW5/kkG55A3Aq8MD8fSVJq2fkp4aq6qUkFwM3A+uA66rq/iSXA/2q2hcK5wI3VFUN7X4s8NkkrzAIpauGnzaSJK2+vPpzeTr0er3q9/uTLkOSpkqSXd092VfxL4slqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0bSxAk2ZLkwSS7k1yywPYLkswlubt7/frQtm1JHupe28ZRjyRp+UaeqjLJOuAa4HRgD3BXktkFppy8saounrfvocBlQA8oYFe37zOj1iVJWp5xnBGcBOyuqkeq6kXgBmDrMvd9P3BLVT3dffjfAmwZQ02SpGUaRxAcCTw2tL6na5vvV5Lck+SmJBtXuC9JLkrST9Kfm5sbQ9mSJFi7m8X/HdhUVT/N4Lf+HSs9QFVtr6peVfVmZmbGXqAktWocQbAX2Di0flTX9iNV9VRVvdCtXgv8o+XuK0laXeMIgruAzUmOSXIwcC4wO9whyRFDq2cBf9Et3wyckWR9kvXAGV2bJGmNjPzUUFW9lORiBh/g64Drqur+JJcD/aqaBf5VkrOAl4CngQu6fZ9O8nsMwgTg8qp6etSaJEnLl6qadA0r1uv1qt/vT7oMSZoqSXZVVW9+u39ZLEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuPGEgRJtiR5MMnuJJcssP2jSR7oJq+/NcnRQ9teTnJ395qdv68kaXWNPENZknXANcDpwB7griSzVfXAULfvAL2qej7JR4B/B/xqt+2HVXXCqHVIkl6fcZwRnATsrqpHqupF4AZg63CHqrq9qp7vVncymKRekvQGMI4gOBJ4bGh9T9e2mAuBrw+tvzlJP8nOJGcvtlOSi7p+/bm5udEqliT9yMiXhlYiyflAD/iFoeajq2pvkncAtyW5t6oenr9vVW0HtsNgzuI1KViSGjCOM4K9wMah9aO6tldJchpwKXBWVb2wr72q9nZfHwG+CZw4hpokScs0jiC4C9ic5JgkBwPnAq96+ifJicBnGYTAk0Pt65Mc0i1vAE4Fhm8yS5JW2ciXhqrqpSQXAzcD64Drqur+JJcD/aqaBX4f+HHgT5IAPFpVZwHHAp9N8gqDULpq3tNGkqRVlqrpu9ze6/Wq3+9PugxJmipJdlVVb367f1ksSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWrcWIIgyZYkDybZneSSBbYfkuTGbvudSTYNbftE1/5gkvePox5J0vKNHARJ1gHXAB8AjgPOS3LcvG4XAs9U1buAq4FPdfsex2CO458CtgD/pTueJGmNjOOM4CRgd1U9UlUvAjcAW+f12Qrs6JZvAt6XweTFW4EbquqFqvoesLs7niRpjYwjCI4EHhta39O1Ldinql4CngMOW+a+ACS5KEk/SX9ubm4MZUuSYIpuFlfV9qrqVVVvZmZm0uVI0gFjHEGwF9g4tH5U17ZgnyQHAT8BPLXMfSVJq2gcQXAXsDnJMUkOZnDzd3Zen1lgW7d8DnBbVVXXfm73VNExwGbg/4yhJknSMh006gGq6qUkFwM3A+uA66rq/iSXA/2qmgU+B3wpyW7gaQZhQdfvj4EHgJeA36yql0etSZK0fBn8Yj5der1e9fv9SZchSVMlya6q6s1vn5qbxZKk1WEQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1LiRgiDJoUluSfJQ93X9An1OSPLtJPcnuSfJrw5t+0KS7yW5u3udMEo9kqSVG/WM4BLg1qraDNzarc/3PPChqvopYAvw6SRvG9r+sao6oXvdPWI9kqQVGjUItgI7uuUdwNnzO1TVd6vqoW75r4AngZkR31eSNCajBsHhVfV4t/wD4PD9dU5yEnAw8PBQ85XdJaOrkxyyn30vStJP0p+bmxuxbEnSPksGQZJvJLlvgdfW4X5VVUDt5zhHAF8CPlxVr3TNnwDeDfwscCjw8cX2r6rtVdWrqt7MjCcUkjQuBy3VoapOW2xbkieSHFFVj3cf9E8u0u+twJ8Bl1bVzqFj7zubeCHJ54HfWVH1kqSRjXppaBbY1i1vA742v0OSg4E/Bb5YVTfN23ZE9zUM7i/cN2I9kqQVGjUIrgJOT/IQcFq3TpJekmu7Ph8Efh64YIHHRL+S5F7gXmADcMWI9UiSViiDS/vTpdfrVb/fn3QZkjRVkuyqqt78dv+yWJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMaNFARJDk1yS5KHuq/rF+n38tCkNLND7cckuTPJ7iQ3drOZSZLW0KhnBJcAt1bVZuDWbn0hP6yqE7rXWUPtnwKurqp3Ac8AF45YjyRphUYNgq3Ajm55B4N5h5elm6f4vcC+eYxXtL8kaTxGDYLDq+rxbvkHwOGL9Htzkn6SnUn2fdgfBjxbVS9163uAIxd7oyQXdcfoz83NjVi2JGmfg5bqkOQbwD9YYNOlwytVVUkWmwD56Kram+QdwG3dhPXPraTQqtoObIfBnMUr2VeStLglg6CqTltsW5InkhxRVY8nOQJ4cpFj7O2+PpLkm8CJwH8D3pbkoO6s4Chg7+sYgyRpBKNeGpoFtnXL24Cvze+QZH2SQ7rlDcCpwANVVcDtwDn721+StLpGDYKrgNOTPASc1q2TpJfk2q7PsUA/yZ8z+OC/qqoe6LZ9HPhokt0M7hl8bsR6JEkrlMEv5tOl1+tVv9+fdBmSNFWS7Kqq3vx2/7JYkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktS4kYIgyaFJbknyUPd1/QJ9finJ3UOvv01ydrftC0m+N7TthFHqkSSt3KhnBJcAt1bVZuDWbv1Vqur2qjqhqk4A3gs8D/yvoS4f27e9qu4esR5J0gqNGgRbgR3d8g7g7CX6nwN8vaqeH/F9JUljMmoQHF5Vj3fLPwAOX6L/ucD189quTHJPkquTHLLYjkkuStJP0p+bmxuhZEnSsCWDIMk3kty3wGvrcL+qKqD2c5wjgOOBm4eaPwG8G/hZ4FDg44vtX1Xbq6pXVb2ZmZmlypYkLdNBS3WoqtMW25bkiSRHVNXj3Qf9k/s51AeBP62qvxs69r6ziReSfB74nWXWLUkak1EvDc0C27rlbcDX9tP3POZdFurCgyRhcH/hvhHrkSSt0KhBcBVwepKHgNO6dZL0kly7r1OSTcBG4H/P2/8rSe4F7gU2AFeMWI8kaYWWvDS0P1X1FPC+Bdr7wK8PrX8fOHKBfu8d5f0lSaPzL4slqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0baWKaJP8U+F3gWOCkbkKahfptAf4AWAdcW1X7ZjI7BrgBOAzYBfzzqnpxlJpa9cmv3suXdz466TKkN4S3HrKOe/7tlkmXMTVGPSO4D/gnwB2LdUiyDrgG+ABwHHBekuO6zZ8Crq6qdwHPABeOWE+TDAHp1f7mhZf56cv+56TLmBojBUFV/UVVPbhEt5OA3VX1SPfb/g3A1m7C+vcCN3X9djCYwF4rdP2dj026BOkN529eeHnSJUyNtbhHcCQw/Em1p2s7DHi2ql6a176gJBcl6Sfpz83NrVqx0+jlqkmXIGmKLRkESb6R5L4FXlvXosB9qmp7VfWqqjczM7OWb/2Gty6ZdAmSptiSN4ur6rQR32MvsHFo/aiu7SngbUkO6s4K9rVrhc47eaP3CKR53nrIukmXMDXW4tLQXcDmJMckORg4F5itqgJuB87p+m0DvrYG9Rxwrjj7eM4/5e2TLkN6w/CpoZVJjXB9OckvA/8JmAGeBe6uqvcn+YcMHhM9s+t3JvBpBo+PXldVV3bt72Bw8/hQ4DvA+VX1wlLv2+v1qt9f8ElVSdIikuyqqt5r2kcJgkkxCCRp5RYLAv+yWJIaZxBIUuMMAklqnEEgSY2bypvFSeaAv3ydu28A/nqM5UwDx9wGx3zgG3W8R1fVa/4idyqDYBRJ+gvdNT+QOeY2OOYD32qN10tDktQ4g0CSGtdiEGyfdAET4Jjb4JgPfKsy3ubuEUiSXq3FMwJJ0hCDQJIad8AGQZItSR5MsjvJJQtsPyTJjd32O5NsWvsqx2cZ4/1okgeS3JPk1iRHT6LOcVpqzEP9fiVJJZn6xwyXM+YkH+y+1/cn+aO1rnHclvGz/fYktyf5TvfzfeYk6hynJNcleTLJfYtsT5L/2P03uSfJz4z0hlV1wL0Y/HPXDwPvAA4G/hw4bl6ffwl8pls+F7hx0nWv8nh/Cfh73fJHpnm8yx1z1+8twB3ATqA36brX4Pu8mcE/6b6+W//7k657Dca8HfhIt3wc8P1J1z2Gcf888DPAfYtsPxP4OhDgFODOUd7vQD0jOAnYXVWPVNWLDOY8mD+15lZgR7d8E/C+ZGrnfFxyvFV1e1U9363uZDAj3DRbzvcY4PeATwF/u5bFrZLljPk3gGuq6hmAqnpyjWsct+WMuYC3dss/AfzVGta3KqrqDuDp/XTZCnyxBnYymO3xiNf7fgdqEBwJPDa0vqdrW7BPDabKfA44bE2qG7/ljHfYhQx+m5hmS465O13eWFV/tpaFraLlfJ9/EvjJJN9KsjPJtE/TtZwx/y5wfpI9wP8AfmttSpuolf4/v19LzlmsA0uS84Ee8AuTrmU1JXkT8B+ACyZcylo7iMHloV9kcNZ3R5Ljq+rZiVa1us4DvlBV/z7JzwFfSvKeqnpl0oVNiwP1jGAvsHFo/aiubcE+SQ5icEr51JpUN37LGS9JTgMuBc6qZUwJ+ga31JjfArwH+GaS7zO4jjo75TeMl/N93sNgTvC/q6rvAd9lEAzTajljvhD4Y4Cq+jbwZgb/ONuBbFn/zy/XgRoEdwGbkxyT5GAGN4Nn5/WZBbZ1y+cAt1V3F2YKLTneJCcCn2UQAtN+3RiWGHNVPVdVG6pqU1VtYnBf5KyqmuY5Tpfzc/1VBmcDJNnA4FLRI2tZ5JgtZ8yPAu8DSHIsgyCYW9Mq194s8KHu6aFTgOeq6vHXe7AD8tJQVb2U5GLgZgZPHVxXVfcnuRzoV9Us8DkGp5C7GdyUOXdyFY9mmeP9feDHgT/p7ok/WlVnTazoES1zzAeUZY75ZuCMJA8ALwMfq6ppPdNd7pj/NfCHSX6bwY3jC6b4lzoAklzPINA3dPc+LgN+DKCqPsPgXsiZwG7geeDDI73flP/3kiSN6EC9NCRJWiaDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXu/wOJC1VIk0CxlgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQVjJLA2E_F6"
      },
      "source": [
        "**Question 7.** We propose to use the following family of (non linear) polynomial predictors $h(x) = {\\bf sign}( \\sum_{i=0}^d w_i x^i)$. Propose a method to perform empirical risk minimization for this family of predictors, based on the perceptron algorithm. Perform the same steps as in question 5. Find a value for the dimension $d$ for which the validation error is low and interpret the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "iSjJ0it4E_F7",
        "outputId": "14335a15-e4a4-4b14-d3c3-8d0d789c4a28"
      },
      "source": [
        "#transform the data using the polynomial mapping \n",
        "d = 4\n",
        "X_poly = np.zeros([X.shape[0],d+1])\n",
        "for i in range(0,X.shape[0]):\n",
        "    X_poly[i,:] = ### FILL HERE\n",
        "#learn on the transformed data\n",
        "T = 10000 #number of iterations\n",
        "n = 100 #number of cross validations\n",
        "t_mean = 0 #to store the average training error\n",
        "v_mean = 0 #to store the average validation error\n",
        "for s in range(0,n):\n",
        "    #Split the data set to perform cross validation\n",
        "    m = 100 #number of examples in the training set\n",
        "    X_train,Y_train,X_eval,Y_eval = split(X_poly,Y,m)\n",
        "    #Run the perceptron algorithm for T iterations over N cross validations\n",
        "    w = perceptron(X_train,Y_train,T)\n",
        "    #Compute the training and validation error of the resulting classifier\n",
        "    t = get_error(X_train,Y_train,w)\n",
        "    v = get_error(X_eval,Y_eval,w)\n",
        "    t_mean = t_mean + t/n\n",
        "    v_mean = v_mean + v/n\n",
        "\n",
        "print('Average Training Error ', t_mean, '\\nAverage Validation Error ',v_mean)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-ab970fdaa30d>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    X_poly[i,:] = ### FILL HERE\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4sA2WpGE_F-",
        "outputId": "92efbd10-b427-432e-acdc-f443c627ef95"
      },
      "source": [
        "#transform the data using the polynomial mapping \r\n",
        "d = 5\r\n",
        "X_poly = np.zeros([X.shape[0],d+1])\r\n",
        "for i in range(0,X.shape[0]):\r\n",
        "    X_poly[i,:] = np.power(X[i],list(range(d+1)))\r\n",
        "#learn on the transformed data\r\n",
        "T = 10000 #number of iterations\r\n",
        "n = 100 #number of cross validations\r\n",
        "t_mean = 0 #to store the average training error\r\n",
        "v_mean = 0 #to store the average validation error\r\n",
        "for s in range(0,n):\r\n",
        "    #Split the data set to perform cross validation\r\n",
        "    m = 100 #number of examples in the training set\r\n",
        "    X_train,Y_train,X_eval,Y_eval = split(X_poly,Y,m)\r\n",
        "    #Run the perceptron algorithm for T iterations over N cross validations\r\n",
        "    w = perceptron(X_train,Y_train,T)\r\n",
        "    #Compute the training and validation error of the resulting classifier\r\n",
        "    t = get_error(X_train,Y_train,w)\r\n",
        "    v = get_error(X_eval,Y_eval,w)\r\n",
        "    t_mean = t_mean + t/n\r\n",
        "    v_mean = v_mean + v/n\r\n",
        " \r\n",
        "print('Average Training Error ', t_mean, '\\nAverage Validation Error ',v_mean)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Training Error  0.0034000000000000002 \n",
            "Average Validation Error  0.014077777777777772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2e_rNJ5LhJ7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}